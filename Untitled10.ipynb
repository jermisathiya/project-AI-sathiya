{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sample dataset containing short stories, poems, and news articles\n",
        "dataset = \"\"\"\n",
        "Once upon a time, there was a brave knight named Sir Lancelot. He lived in a castle on the edge of the kingdom, guarding it from all evil.\n",
        "\n",
        "In a faraway land, there was a magical forest where fairies and elves lived in harmony. But one day, darkness crept into the forest, threatening to destroy everything.\n",
        "\n",
        "I wandered lonely as a cloud That floats on high o'er vales and hills, When all at once I saw a crowd, A host, of golden daffodils;\n",
        "\n",
        "The woods are lovely, dark and deep, But I have promises to keep, And miles to go before I sleep, And miles to go before I sleep.\n",
        "\n",
        "Scientists have discovered a new species of deep-sea fish in the Mariana Trench. The fish, named Mariana snailfish, thrives in the extreme conditions of the trench.\n",
        "\n",
        "The stock market experienced a sharp decline today, with major indices dropping by over 5%. Analysts attribute the downturn to concerns over inflation and geopolitical tensions.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([dataset])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Generate input sequences\n",
        "input_sequences = []\n",
        "for line in dataset.split('\\n'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "# One-hot encode the label\n",
        "label = np.eye(total_words)[label.astype(int)]\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(predictors, label, epochs=100, verbose=1, batch_size=32)\n",
        "\n",
        "# Generate text\n",
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Example usage\n",
        "seed_text = \"once upon a time\"\n",
        "generated_text = generate_text(seed_text, 10, model, max_sequence_len)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJiMQfUEnUjS",
        "outputId": "a171c79c-16c9-436d-e7b8-43daff503b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 157 samples\n",
            "Epoch 1/100\n",
            "157/157 [==============================] - 1s 9ms/sample - loss: 4.6741 - accuracy: 0.0191\n",
            "Epoch 2/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 4.6485 - accuracy: 0.0764\n",
            "Epoch 3/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 4.5759 - accuracy: 0.0637\n",
            "Epoch 4/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 4.4688 - accuracy: 0.0637\n",
            "Epoch 5/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 4.3863 - accuracy: 0.1019\n",
            "Epoch 6/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 4.2759 - accuracy: 0.0955\n",
            "Epoch 7/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 4.1663 - accuracy: 0.0892\n",
            "Epoch 8/100\n",
            "157/157 [==============================] - 1s 3ms/sample - loss: 4.0441 - accuracy: 0.1083\n",
            "Epoch 9/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 3.9190 - accuracy: 0.1019\n",
            "Epoch 10/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 3.7970 - accuracy: 0.1083\n",
            "Epoch 11/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 3.7083 - accuracy: 0.1146\n",
            "Epoch 12/100\n",
            "157/157 [==============================] - 1s 6ms/sample - loss: 3.5825 - accuracy: 0.1401\n",
            "Epoch 13/100\n",
            "157/157 [==============================] - 1s 5ms/sample - loss: 3.4326 - accuracy: 0.1465\n",
            "Epoch 14/100\n",
            "157/157 [==============================] - 1s 6ms/sample - loss: 3.3252 - accuracy: 0.1401\n",
            "Epoch 15/100\n",
            "157/157 [==============================] - 1s 5ms/sample - loss: 3.2257 - accuracy: 0.1465\n",
            "Epoch 16/100\n",
            "157/157 [==============================] - 1s 3ms/sample - loss: 3.1979 - accuracy: 0.1465\n",
            "Epoch 17/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 3.0684 - accuracy: 0.1656\n",
            "Epoch 18/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.9750 - accuracy: 0.1975\n",
            "Epoch 19/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.8877 - accuracy: 0.1592\n",
            "Epoch 20/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.8032 - accuracy: 0.2229\n",
            "Epoch 21/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.7413 - accuracy: 0.2166\n",
            "Epoch 22/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.6764 - accuracy: 0.2357\n",
            "Epoch 23/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.5640 - accuracy: 0.2548\n",
            "Epoch 24/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.5102 - accuracy: 0.2930\n",
            "Epoch 25/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.4650 - accuracy: 0.2930\n",
            "Epoch 26/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.3636 - accuracy: 0.3376\n",
            "Epoch 27/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.2964 - accuracy: 0.3694\n",
            "Epoch 28/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.2112 - accuracy: 0.3949\n",
            "Epoch 29/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.1759 - accuracy: 0.3567\n",
            "Epoch 30/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.1469 - accuracy: 0.3885\n",
            "Epoch 31/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.1288 - accuracy: 0.3567\n",
            "Epoch 32/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.0438 - accuracy: 0.4522\n",
            "Epoch 33/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.0084 - accuracy: 0.4204\n",
            "Epoch 34/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.9792 - accuracy: 0.4076\n",
            "Epoch 35/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 2.0123 - accuracy: 0.3376\n",
            "Epoch 36/100\n",
            "157/157 [==============================] - 1s 4ms/sample - loss: 1.9579 - accuracy: 0.4204\n",
            "Epoch 37/100\n",
            "157/157 [==============================] - 1s 6ms/sample - loss: 1.8727 - accuracy: 0.4968\n",
            "Epoch 38/100\n",
            "157/157 [==============================] - 1s 6ms/sample - loss: 1.8356 - accuracy: 0.4650\n",
            "Epoch 39/100\n",
            "157/157 [==============================] - 1s 5ms/sample - loss: 1.7690 - accuracy: 0.5541\n",
            "Epoch 40/100\n",
            "157/157 [==============================] - 1s 5ms/sample - loss: 1.7466 - accuracy: 0.5987\n",
            "Epoch 41/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.7047 - accuracy: 0.5796\n",
            "Epoch 42/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.6709 - accuracy: 0.5987\n",
            "Epoch 43/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.6411 - accuracy: 0.5924\n",
            "Epoch 44/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.5771 - accuracy: 0.6688\n",
            "Epoch 45/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.5527 - accuracy: 0.6624\n",
            "Epoch 46/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.5115 - accuracy: 0.6943\n",
            "Epoch 47/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.4984 - accuracy: 0.6943\n",
            "Epoch 48/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.4968 - accuracy: 0.6115\n",
            "Epoch 49/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.4985 - accuracy: 0.5987\n",
            "Epoch 50/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.5208 - accuracy: 0.5478\n",
            "Epoch 51/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.5065 - accuracy: 0.5860\n",
            "Epoch 52/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.4608 - accuracy: 0.6688\n",
            "Epoch 53/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.4122 - accuracy: 0.6879\n",
            "Epoch 54/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.3754 - accuracy: 0.6879\n",
            "Epoch 55/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.3679 - accuracy: 0.6497\n",
            "Epoch 56/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.3405 - accuracy: 0.7134\n",
            "Epoch 57/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.2872 - accuracy: 0.7516\n",
            "Epoch 58/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.2737 - accuracy: 0.7134\n",
            "Epoch 59/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.2902 - accuracy: 0.6497\n",
            "Epoch 60/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.2998 - accuracy: 0.6752\n",
            "Epoch 61/100\n",
            "157/157 [==============================] - 1s 5ms/sample - loss: 1.2756 - accuracy: 0.6879\n",
            "Epoch 62/100\n",
            "157/157 [==============================] - 1s 6ms/sample - loss: 1.2353 - accuracy: 0.7452\n",
            "Epoch 63/100\n",
            "157/157 [==============================] - 1s 6ms/sample - loss: 1.1909 - accuracy: 0.7834\n",
            "Epoch 64/100\n",
            "157/157 [==============================] - 1s 6ms/sample - loss: 1.1693 - accuracy: 0.7771\n",
            "Epoch 65/100\n",
            "157/157 [==============================] - 1s 4ms/sample - loss: 1.1325 - accuracy: 0.7962\n",
            "Epoch 66/100\n",
            "157/157 [==============================] - 1s 3ms/sample - loss: 1.1072 - accuracy: 0.8089\n",
            "Epoch 67/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.0794 - accuracy: 0.7898\n",
            "Epoch 68/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.0653 - accuracy: 0.8025\n",
            "Epoch 69/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.0430 - accuracy: 0.8089\n",
            "Epoch 70/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.0346 - accuracy: 0.8217\n",
            "Epoch 71/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.0159 - accuracy: 0.8153\n",
            "Epoch 72/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.9990 - accuracy: 0.8153\n",
            "Epoch 73/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.9855 - accuracy: 0.8217\n",
            "Epoch 74/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.9938 - accuracy: 0.8280\n",
            "Epoch 75/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.0163 - accuracy: 0.8025\n",
            "Epoch 76/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.9850 - accuracy: 0.8025\n",
            "Epoch 77/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.9888 - accuracy: 0.7962\n",
            "Epoch 78/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.9849 - accuracy: 0.7771\n",
            "Epoch 79/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.9818 - accuracy: 0.7962\n",
            "Epoch 80/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.0180 - accuracy: 0.7580\n",
            "Epoch 81/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.0504 - accuracy: 0.7325\n",
            "Epoch 82/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.0642 - accuracy: 0.7452\n",
            "Epoch 83/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.0906 - accuracy: 0.7006\n",
            "Epoch 84/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 1.0424 - accuracy: 0.7580\n",
            "Epoch 85/100\n",
            "157/157 [==============================] - 1s 3ms/sample - loss: 1.0396 - accuracy: 0.7261\n",
            "Epoch 86/100\n",
            "157/157 [==============================] - 1s 6ms/sample - loss: 0.9980 - accuracy: 0.7580\n",
            "Epoch 87/100\n",
            "157/157 [==============================] - 1s 6ms/sample - loss: 0.9473 - accuracy: 0.8089\n",
            "Epoch 88/100\n",
            "157/157 [==============================] - 1s 6ms/sample - loss: 0.8993 - accuracy: 0.8217\n",
            "Epoch 89/100\n",
            "157/157 [==============================] - 1s 6ms/sample - loss: 0.8638 - accuracy: 0.8344\n",
            "Epoch 90/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.8383 - accuracy: 0.8535\n",
            "Epoch 91/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.8271 - accuracy: 0.8471\n",
            "Epoch 92/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.8032 - accuracy: 0.8471\n",
            "Epoch 93/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.8003 - accuracy: 0.8599\n",
            "Epoch 94/100\n",
            "157/157 [==============================] - 1s 3ms/sample - loss: 0.7985 - accuracy: 0.8471\n",
            "Epoch 95/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.7706 - accuracy: 0.8535\n",
            "Epoch 96/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.7623 - accuracy: 0.8662\n",
            "Epoch 97/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.7805 - accuracy: 0.8726\n",
            "Epoch 98/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.8125 - accuracy: 0.8344\n",
            "Epoch 99/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.8474 - accuracy: 0.7834\n",
            "Epoch 100/100\n",
            "157/157 [==============================] - 0s 3ms/sample - loss: 0.8489 - accuracy: 0.7962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "once upon a time there was a a knight named sir lancelot he lived\n"
          ]
        }
      ]
    }
  ]
}